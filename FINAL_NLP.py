# -*- coding: utf-8 -*-
"""Iron man.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V_O1EQ0V26IIJFCPpuDAWCSycOD0klbN

# Natural Language Process Exam

## Imports
"""

!pip install demoji
!pip install emoji
!pip install langdetect
!pip install nltk
!pip install tensorflow
!pip install tqdm
!pip install transformers
!pip install umap
!pip upgrade sklearn

import csv
import demoji
import emoji
import matplotlib.pyplot as plt
import nltk
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns
import string
import tensorflow as tf
import time
import torch
import random

from nltk.corpus import stopwords
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MultiLabelBinarizer
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
from transformers import AutoModelForSequenceClassification, AutoTokenizer, RobertaTokenizer, RobertaForSequenceClassification, AdamW
from tabulate import tabulate


nltk.download('punkt')
nltk.download('stopwords')
nltk.download('vader_lexicon')

"""## Setting working directory"""

# Mounting the drive into Google Drive's directory
#from google.colab import drive
#drive.mount('/content/gdrive/', force_remount=True)
#%cd gdrive/MyDrive

"""## Reading the dataset into a dataframe"""

class TweetTrainingExample:
    """Holds a tweet training example"""
    # Initiate tweet instance
    def __init__(self, id, text, label):
        self.id = id
        self.text = text
        self.label = label
    # Represent tweet example as a formatted string  
    def __repr__(self):
        return str.format('{}, {}, {}\n', self.id, self.label, self.text)

random.seed(10)
# Load example tweets
loaded_data = pd.read_pickle('examples.p')

# Create a dataframe from the loaded tweets:
df = pd.DataFrame.from_records([(value.id, value.label, value.text) 
                                for value in loaded_data.values()], 
                               columns=['ID', 'Sentiment', 'Text'])

# Shuffle the dataframe
df = df.sample(frac=1)

"""## Exploratory Data Analysis (EDA)"""

# Get basic information on the dataset
df.info()

# Print first 10 examples
df.head(10)

"""### Check of Duplicates"""

# Check for duplicate tweets using the ID column
df = df.drop_duplicates(subset=["ID"], keep='first')

# Drop the ID column as it no longer is needed
df = df.drop('ID', axis=1)

"""### Check of NaNs"""

# Pivot Table of NaNs for the different sentiment categories

text_missing_count = df["Text"].isna().sum()
pivot_table = pd.pivot_table(df, values='Text', index='Sentiment', aggfunc=lambda x: x.isna().sum())
pivot_table.loc['Total'] = text_missing_count
pivot_table.rename(columns={'Text': 'NaN'}, inplace=True)
pivot_table = pivot_table.transpose()

pivot_table

# Dropping NaNs
df = df.replace(to_replace='None', value=np.nan).dropna()

"""### Sentiment Analysis"""

def plot_sentiment(df): 
    '''
    Takes the dataframe of tweets and sentiments. 
    Outputs a bar plot of the number of tweets for each category of sentiment.
    '''
    # Map the sentiment labels to their corresponding names
    sentiment_mapping = {"-1": "Negative", "0": "Neutral", "1": "Positive"}

    def map_sentiment_label(label):
        # Map the label if it matches the mapping, otherwise keep it in its original format
        return sentiment_mapping.get(str(label), label)

    df_copy = df.copy()
    df_copy["Sentiment"] = df_copy["Sentiment"].apply(map_sentiment_label)

    function = df_copy["Sentiment"].value_counts()

    # Sort the values based on the original labels
    function = function.reindex(list(sentiment_mapping.values()), fill_value=0)

    total_count = function.sum()
    percentages = (function / total_count) * 100

    fig, ax = plt.subplots(figsize=(6, 4))
    bars = plt.bar(function.index, function.values, color='skyblue')

    for bar, count, percentage in zip(bars, function.values, percentages):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{count}\n({percentage:.1f}%)', ha='center', va='bottom')

    plt.xlabel('Sentiment')
    plt.ylabel('Count')
    plt.title('Sentiment Distribution')
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    ax.set_ylim(top=max(function.values) * 1.15)

    plt.show()

plot_sentiment(df)

"""### Emoji Presence Analysis"""

def plot_emoji(df):
    '''
    A function that enables the plotting of values present in the dataframe.
    Takes the dataframe as input and outputs a bar plot based on "Sentiment" and "Has_Emoji" columns.
    '''
    df['Text'] = df['Text'].astype(str)

    df['Has_Emoji'] = df['Text'].apply(lambda text: emoji.emoji_count(text) > 0)

    function = df.groupby('Sentiment')['Has_Emoji'].value_counts().unstack().fillna(0)[::-1]

    fig, ax = plt.subplots(figsize=(8, 4))  # Adjust the figure size as desired
    bars = function.plot(kind='bar', ax=ax)

    total_counts = function.sum(axis=1)
    total_percentages = (total_counts / total_counts.sum()) * 100

    for rect in bars.patches:
        height = rect.get_height()
        ax.annotate(f'{int(height)}', xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')

    for rect, sentiment in zip(bars.patches, function.index):
        height = rect.get_height()
        true_percentage = (function.loc[sentiment, True] / total_counts.loc[sentiment]) * 100
        false_percentage = (function.loc[sentiment, False] / total_counts.loc[sentiment]) * 100
        
        ax.annotate(f'{true_percentage:.1f}% True', xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(+20, -15), textcoords="offset points", ha='left', va='center', color='black')
        
        ax.annotate(f'{false_percentage:.1f}% False', xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(+20, -30), textcoords="offset points", ha='left', va='center', color='black')

    plt.xlabel('Sentiment')
    plt.xticks(rotation = 0)
    plt.ylabel('Count')
    plt.title('Emoji Presence by Sentiment')
    plt.legend(title='Emoji', loc='upper right', labels=['Emojis Present', 'No Emojis Present'])
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    
    ax.set_ylim(top=max(total_counts.values) * 1)

    plt.show()

    df.drop("Has_Emoji", axis=1, inplace=True)

plot_emoji(df)

"""## Pre-processing of Main Dataset"""

def preprocess_text(df):
    '''
    Takes a dataframe as input considers the "Text" column. 
    Applies processing to the different texts in the dataframe, stripping it from unnecessary elements.
    So that the function is idempotent, the value is confirmed to be a string before applying any string operations.
    If the value is not a string, it returns the original value without any changes.
    '''
    # Dropping NaNs
    df = df.replace(to_replace='None', value=np.nan).dropna()

    # Convert tweets to strings
    df['Text'] = df['Text'].astype(str)
    
    # Remove @user
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'@\S+', '', x) if isinstance(x, str) else x)

    # Remove URLs
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'http\S+', '', x) if isinstance(x, str) else x)

    # Remove #'s
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'#', '', x) if isinstance(x, str) else x)
    
    # Remove 'RT' from Retweeted Tweets
    df['Text'] = df['Text'].apply(lambda x: re.sub(r'^RT\s+', '', x) if isinstance(x, str) else x)

    # Remove multiple consecutive spaces
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'\s+', ' ', x) if isinstance(x, str) else x)

    # Map the sentiments to numerical values
    sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}
    df['Sentiment'] = df['Sentiment'].map(sentiment_mapping)

    return df

def convert_abbrev(df):
    ''' 
    Takes a dataframe and replaces popular abbreviations with corresponding words/sentences.
    '''
    csv_file = "abbreviations.csv"

    # Read the CSV file and store its contents in a dictionary
    abbreviations = {}
    with open(csv_file, "r", encoding="utf-8") as file:
        reader = csv.DictReader(file)
        for row in reader:
            abbreviation = row["Abbreviation"]
            expansion = row["Expansion"]
            abbreviations[abbreviation] = expansion
            
    # Create pattern for replacing words that are abbreviations
    pattern = r'\b({})\b'.format('|'.join(map(re.escape, abbreviations.keys())))
    
    # Replace abbrevations
    df['Text'] = df['Text'].str.replace(pattern, lambda m: abbreviations[m.group()], regex=True)
    
    return df

# Apply pre-processing steps to main dataset
df = preprocess_text(df)

# Translate abbreviations in tweets
df = convert_abbrev(df)

# examples of cleaned tweets
df.head(10)

# Sentiment distribution after pre-processing
plot_sentiment(df)

"""## Pre-processing of Dataset Variations

The goal in this processing is to create three variations of the main dataset that vary in their treatment of emojis:

| DataFrame | Processed Text             | Original Emojis | Translated Emojis | Emojis Removed |
|-----------|----------------------------|-------------|-----------------|----------------|
| df1       | Yes | Yes         | No              | No             |
| df1_1     | Yes | No          | Yes             | No             |
| df2       | Yes             | No          | No              | Yes            |

- Original Emojis imply the image-like emojis
- Translated Emojis implies the use of the function emoji.demojize(X);
- Emojis removed implies the use of the function remove_emojis(X).

### df1
"""

# df1 is simply a copy of the main dataset, df
df1 = df.copy()

df1.head(10)

"""### df1_1"""

def new_space(df):
    '''
    After the translation of the emoji, this function will add a space between the translated text of the emojis.
    The function takes a dataframe as input.
    The output is also a dataframe.
    '''
    # Add spaces
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'[:_]', ' ', x) if isinstance(x, str) else x)

    return df

df1_1 = df.copy()

# Translate emojis to text
df1_1["Text"] = df1_1["Text"].apply(lambda x: emoji.demojize(x))

# Adding space on the translated emojis
df1_1.loc[:, 'Text'] = df1_1['Text'].apply(lambda x: re.sub(r'[:_]', ' ', x) if isinstance(x, str) else x)

df1_1.head(60)

"""### df2"""

def remove_emojis(df):
    """
    Remove emojis from a DataFrame.
    Takes a DataFrame as input and removes emoji characters from all text columns.
    Returns a new DataFrame with emojis removed.
    """
    # Define the regex pattern for emoji characters
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               u"\U00002702-\U000027B0"  # other miscellaneous symbols
                               u"\U000024C2-\U0001F251" 
                               "]+", flags=re.UNICODE)
    
    # Apply the regex pattern to all text columns in the DataFrame
    cleaned_df = df.copy()  # Make a copy of the original DataFrame
    cleaned_df["Text"] = cleaned_df["Text"].apply(lambda text: emoji_pattern.sub(r'', str(text)))

    return cleaned_df

df2 = df.copy()
# Remove emojis
df2 = remove_emojis(df2)

# Confirming if emojis have been removed from individual tweets
df2.head()

"""# Train, Validation and Test Split"""

def split_data(df, test_size=0.15, val_size=0.15, random_state=10):
    
    # Calculate the total size that should be set aside for test and validation
    test_val_size = test_size + val_size
    
    # Split texts and sentiments into train and test sets
    train_df, remaining_df = train_test_split(df, test_size=test_val_size)

    # Calculate the size that should be set size aside for validation
    val_split = val_size/(test_size+val_size)
    
    # Split test set into validation and test set
    test_df, val_df = train_test_split(remaining_df, test_size=val_split)

    # Print the number of rows in each split
    print("Train set size:", train_df.shape[0],"(",100*(1-test_val_size),"%)")
    print("Validation set size:", val_df.shape[0],"(",100*(val_size),"%)")
    print("Test set size:", test_df.shape[0],"(",100*(test_size),"%)")

    return train_df, val_df, test_df

# Split the three dataset variations
df1_train, df1_val, df1_test = split_data(df1, val_size = 0.15, test_size = 0.15)
df1_1_train, df1_1_val, df1_1_test = split_data(df1_1, val_size = 0.15, test_size = 0.15)
df2_train, df2_val, df2_test = split_data(df2, val_size = 0.15, test_size = 0.15)

# DF1 FOR VADER and RandomForest (VRF)
vrf_df1_train = df1_train.copy()
vrf_df1_val = df1_val.copy()
vrf_df1_test = df1_test.copy()

# DF1_1 FOR VADER and RandomForest (VRF)
vrf_df1_1_train = df1_1_train.copy()
vrf_df1_1_val = df1_1_val.copy()
vrf_df1_1_test = df1_1_test.copy()

# DF2 FOR VADER and RandomForest (VRF)
vrf_df2_train = df2_train.copy()
vrf_df2_val = df2_val.copy()
vrf_df2_test = df2_test.copy()

"""# Model evalution

### Plot confusion matrix
"""

def plot_confusion_matrix(y_true, y_pred):
    """
    Plot the confusion matrix using a heatmap.
    
    Args:
        y_true: True labels.
        y_pred: Predicted labels.
    """
    cm = confusion_matrix(y_true, y_pred)
    class_labels = ['Negative', 'Neutral', 'Positive']

    plt.figure(figsize=(4, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

"""### Classification report"""

def class_report(y_true, y_pred):
  """
  Create confusion matrix using proper class labels.
  
  Args:
    y_true: True labels.
    y_pred: Predicted labels.
  """
  class_labels = ['Negative', 'Neutral', 'Positive']
  return classification_report(y_true, y_pred, target_names=class_labels, digits=4)

"""# Further Processing for non-BERT/non-context models"""

def add_space_between_emojis(sentence):
    '''
    Identifies emojis; 
    When employed adds a space between consecutive ones.
    '''
    emojis = demoji.findall(sentence)
    
    for emoji in emojis:
        sentence = sentence.replace(emoji, ' ' + emoji + ' ')  # Add space before and after each emoji
    
    return sentence.strip()  # Remove leading/trailing spaces

def pre_process_text2(df):
    '''
    these steps should most likely only be applied to the baseline model
    '''
    # Remove punctuation and other specific characters
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'[{}]'.format(re.escape(string.punctuation + '“”’‘')), '', x) if isinstance(x, str) else x)

    # Converting "Text" column to lower case
    df.loc[:,'Text'] = df['Text'].str.lower()

    # Remove numbers
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: re.sub(r'\d+', '', x) if isinstance(x, str) else x)

    # Remove stopwords
    stopwords_set = set(stopwords.words('english'))
    df.loc[:, 'Text'] = df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stopwords_set]) if isinstance(x, str) else x)
    
    # Applying the spaces_in_emojis
    df['Text'] = df['Text'].apply(lambda x: add_space_between_emojis(x))

    return df

variables = [
    vrf_df1_train, vrf_df1_val, vrf_df1_test,
    vrf_df1_1_train, vrf_df1_1_val, vrf_df1_1_test,
    vrf_df2_train, vrf_df2_val, vrf_df2_test]

# Apply the pre_process_text2 function to variables using a for loop
for variable in variables:
    variable = pre_process_text2(variable)

"""# The Models

# Vader
"""

def vader(df):
  # Initialize the sentiment scorer
  SIA = SentimentIntensityAnalyzer()

  # Create a list for storing predicted sentiments
  predicted_sentiments = []

  # Iterate over each tweet
  for index, row in df.iterrows():
      tweet = str(row['Text'])

      # Perform sentiment scoring
      sentiment_score = SIA.polarity_scores(tweet)

      # Assign sentiment label
      if sentiment_score['compound'] >= 0.05:
          predicted_sentiment = 1 
      elif sentiment_score['compound'] <= -0.05:
          predicted_sentiment = -1
      else:
          predicted_sentiment = 0
      # Append the predicted sentiment label to the list
      predicted_sentiments.append(predicted_sentiment)

  return predicted_sentiments

# Run Vader on each dataset variation
predicted_sentiments1 = vader(vrf_df1_val)
predicted_sentiments1_1 = vader(vrf_df1_1_val)
predicted_sentiments2 = vader(vrf_df2_val)

# Get classification reports for each run
print('with emojis (df1)')
print(class_report(list(vrf_df1_val['Sentiment']), predicted_sentiments1))
print('with translated emojis (df1_1)')
print(class_report(list(vrf_df1_1_val['Sentiment']), predicted_sentiments1_1))
print('Without emojis (df2)')
print(class_report(list(vrf_df2_val['Sentiment']), predicted_sentiments2))

# Run Vader on each dataset variation
predicted_sentiments1 = vader(vrf_df1_test)
predicted_sentiments1_1 = vader(vrf_df1_1_test)
predicted_sentiments2 = vader(vrf_df2_test)

# Get classification reports for each run
print('df1 (with emojis)')
print(class_report(list(vrf_df1_test['Sentiment']), predicted_sentiments1))
print('df1_1 (with translated emojis)')
print(class_report(list(vrf_df1_1_test['Sentiment']), predicted_sentiments1_1))
print('df2 (without emojis)')
print(class_report(list(vrf_df2_test['Sentiment']), predicted_sentiments2))

"""
# RandomForest"""

# Tokenize function
def tokenize(text):
    tokens = word_tokenize(text)
    return tokens

variables = [
    vrf_df1_train, vrf_df1_val, vrf_df1_test,
    vrf_df1_1_train, vrf_df1_1_val, vrf_df1_1_test,
    vrf_df2_train, vrf_df2_val, vrf_df2_test]

for df in variables:
    df["Text"] = df["Text"].apply(tokenize)

datasets = {
    "vrf_df1_train": vrf_df1_train,
    "vrf_df1_val": vrf_df1_val,
    "vrf_df1_test": vrf_df1_test,
    "vrf_df1_1_train": vrf_df1_1_train,
    "vrf_df1_1_val": vrf_df1_1_val,
    "vrf_df1_1_test": vrf_df1_1_test,
    "vrf_df2_train": vrf_df2_train,
    "vrf_df2_val": vrf_df2_val,
    "vrf_df2_test": vrf_df2_test
}

data_variables = ["Sentiment", "Text"]

# Collect the variable names in a list
variable_names = []

# Create variables for each dataset variable
original_dataframes = [
    vrf_df1_train, vrf_df1_val, vrf_df1_test,
    vrf_df1_1_train, vrf_df1_1_val, vrf_df1_1_test,
    vrf_df2_train, vrf_df2_val, vrf_df2_test
]

for dataset_name, dataset in datasets.items():
    if any(id(dataset) == id(df) for df in original_dataframes):
        for variable_name in data_variables:
            updated_variable_name = dataset_name + "_" + variable_name
            globals()[updated_variable_name] = dataset[variable_name]
            variable_names.append(updated_variable_name)

# Print the variable names
print("Available variables:")
for variable_name in variable_names:
    print(variable_name)

def lemmatize_text(df):
    if isinstance(df, str):
        lemmatizer = WordNetLemmatizer()
        lemmatized_words = [lemmatizer.lemmatize(word) for word in df]
        lemmatized_text = ' '.join(lemmatized_words)
        return lemmatized_text
    else:
        return df

"""## Running code for RandomForest"""

def random_forest_train(X_train, y_train, X_val, n_estimators=100, criterion="gini", max_features='sqrt'):
    # Convert tokenized text data into numerical features
    mlb = MultiLabelBinarizer()
    X_train_vectorized = mlb.fit_transform(X_train)
    X_val_vectorized = mlb.transform(X_val)

    # Train the Random Forest classifier
    rf = RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, criterion=criterion, max_features=max_features, verbose=1, warm_start=True)
    rf.fit(X_train_vectorized, y_train)

    # Make predictions on the val/test set
    predictions = rf.predict(X_val_vectorized)

    return predictions

"""### Initial Results"""

predictions_df1 = random_forest_train(vrf_df1_train_Text, vrf_df1_train_Sentiment, vrf_df1_val_Text)

# Evaluate the model
print(class_report(vrf_df1_val_Sentiment, predictions_df1))
print(plot_confusion_matrix(vrf_df1_val_Sentiment, predictions_df1))

predictions_df1_1 = random_forest_train(vrf_df1_1_train_Text, vrf_df1_1_train_Sentiment, vrf_df1_1_val_Text)

# Evaluate the model
print(class_report(vrf_df1_1_val_Sentiment, predictions_df1_1))
print(plot_confusion_matrix(vrf_df1_1_val_Sentiment, predictions_df1_1))

predictions_df2 = random_forest_train(vrf_df2_train_Text, vrf_df2_train_Sentiment, vrf_df2_val_Text)

# Evaluate the model
print(class_report(vrf_df2_val_Sentiment, predictions_df2))
print(plot_confusion_matrix(vrf_df2_val_Sentiment, predictions_df2))

"""## Tuning

### Criterion
"""

tune_1_df1 = random_forest_train(vrf_df1_train_Text, vrf_df1_train_Sentiment, vrf_df1_val_Text, criterion = "entropy")

# Evaluate the model
print(class_report(vrf_df1_val_Sentiment, tune_1_df1))
print(plot_confusion_matrix(vrf_df1_val_Sentiment, tune_1_df1))

"""###Grid Search"""

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MultiLabelBinarizer

def grid_search_random_forest(X_train, y_train, X_val):

    # Convert tokenized text data into numerical features
    mlb = MultiLabelBinarizer()
    X_train_vectorized = mlb.fit_transform(X_train)
    X_val_vectorized = mlb.transform(X_val)

    param_grid = {
        'max_features': ['sqrt', 'log2'],
        'n_estimators': [10, 25, 50, 75, 100, 150, 200 ]
    }


    grid_search = GridSearchCV(RandomForestClassifier(criterion="entropy", verbose=1, warm_start=True, n_jobs=-1), param_grid, cv=3)
    grid_search.fit(X_train_vectorized, y_train)

    best_params = grid_search.best_params_
    print("Best Parameters:", best_params)

    # Assign best parameter values to variables
    best_max_features = best_params['max_features']
    best_n_estimators = best_params['n_estimators']

    return best_max_features, best_n_estimators

b_max_features, b_n_estimators = grid_search_random_forest(vrf_df1_train_Text, vrf_df1_train_Sentiment, vrf_df1_val_Text)

# Print best hyper parameters
print("Best max_features:", b_max_features)
print("Best n_estimators:", b_n_estimators)

"""## Testing"""

# With emojis (df1)
final_predictions_df1 = random_forest_train(vrf_df1_train_Text, vrf_df1_train_Sentiment, vrf_df1_test_Text, max_features='sqrt', n_estimators=150, criterion='entropy')
cr_1 = class_report(vrf_df1_test_Sentiment, final_predictions_df1)

print(cr_1)
print(plot_confusion_matrix(vrf_df1_test_Sentiment, final_predictions_df1))

# With translated emojis (df1_1)
final_predictions_df1_1 = random_forest_train(vrf_df1_1_train_Text, vrf_df1_1_train_Sentiment, vrf_df1_1_test_Text, max_features='sqrt', n_estimators=150, criterion='entropy')
cr1_1 = class_report(vrf_df1_1_test_Sentiment, final_predictions_df1_1)

print(cr1_1)
print(plot_confusion_matrix(vrf_df1_1_test_Sentiment, final_predictions_df1_1))

# Without emojis (df2)
final_predictions_df2 = random_forest_train(vrf_df2_train_Text, vrf_df2_train_Sentiment, vrf_df2_test_Text, max_features='sqrt', n_estimators=150, criterion='entropy')
cr2 = class_report(vrf_df2_test_Sentiment, final_predictions_df2)

print(cr2)
print(plot_confusion_matrix(vrf_df2_test_Sentiment, final_predictions_df2))

"""# RoBERTa

### GPU check
"""

# Set Pytorch to use GPU:
if torch.cuda.is_available():
 device = torch.device("cuda") 
 print('GPU is enabled for Pytorch')
else:
  print('GPU is not enabled for Pytorch')

"""### Training"""

def RoBERTa_train(df, learning_rate=6e-6, epochs=1, batch_size=32):
    
    # Set max length of input that can fit any tokenized
    max_length = 140
    # Define a custom dataset class
    class CustomDataset(Dataset):
        def __init__(self, dataframe, tokenizer, max_length, label_encoder):
            self.data = dataframe
            self.tokenizer = tokenizer
            self.max_length = max_length
            self.label_encoder = label_encoder

        def __len__(self):
            return len(self.data)

        def __getitem__(self, index):
            text = str(self.data.iloc[index]['Text'])
            label = self.data.iloc[index]['Sentiment']
            encoding = self.tokenizer.encode_plus(
                text,
                add_special_tokens=True,
                max_length=self.max_length,
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            )
            input_ids = encoding['input_ids'].squeeze()
            attention_mask = encoding['attention_mask'].squeeze()
            label = self.label_encoder.transform([label])[0]

            return {
                'input_ids': input_ids,
                'attention_mask': attention_mask,
                'label': torch.tensor(label)
            }

    # Load the tokenizer and model
    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)

    # Encode labels
    label_encoder = LabelEncoder()
    labels = df['Sentiment']
    label_encoder.fit(labels)

    # Prepare the data
    dataset = CustomDataset(df, tokenizer, max_length, label_encoder)
    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Set up the optimizer and scheduler
    optimizer = AdamW(model.parameters(), lr=learning_rate)
    total_steps = len(train_loader) * epochs
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)

    # Training loop with progress bar
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.train()
    for epoch in range(epochs):
        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}', leave=False)

        for batch in progress_bar:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            optimizer.zero_grad()
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss

            loss.backward()
            optimizer.step()
            scheduler.step()

            progress_bar.set_postfix({'Loss': loss.item()})
            progress_bar.update()

        progress_bar.close()

    # Save the trained model
    model.save_pretrained('trained_model')
    tokenizer.save_pretrained('trained_model')

    # GPU memory management, delete tensors and clear cache 
    dataset.data, dataset.tokenizer, dataset.label_encoder = None, None, None
    model, tokenizer, optimizer, scheduler = None, None, None, None
    input_ids, attention_mask, labels, outputs, loss = None, None, None, None, None
    torch.cuda.empty_cache()

"""### Inference"""

def RoBERTa_predict(df):
    # Define the model and tokenizer paths in the current working directory
    model_name = 'trained_model'
    model_path = os.path.join(os.getcwd(), model_name)
    tokenizer_path = os.path.join(os.getcwd(), model_name)

    # Load the saved model and tokenizer
    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)

    # Get the texts from the dataframe column
    texts = df['Text'].tolist()

    # Set number of parrelel inferences
    batch_size = 256

    # Preprocess and predict in batches
    predicted_labels = []
    num_texts = len(texts)

    with tqdm(total=num_texts, desc="Predicting labels") as pbar:
        for i in range(0, num_texts, batch_size):
            batch_texts = texts[i:i+batch_size]

            # Preprocess the input data
            inputs = tokenizer.batch_encode_plus(
                batch_texts,
                add_special_tokens=True,
                return_tensors='pt',
                padding='max_length',
                truncation=True
            )

            # Move inputs to the same device as the model
            inputs = {key: tensor.to(device) for key, tensor in inputs.items()}

            # Perform the prediction
            with torch.no_grad():
                outputs = model(**inputs)

            # Extract the predicted labels
            batch_predicted_labels = torch.argmax(outputs.logits, dim=1)
            predicted_labels.extend(batch_predicted_labels.tolist())

            # Update the progress bar
            pbar.update(len(batch_texts))

    # Map the predicted labels
    label_mapping = {0: -1, 1: 0, 2: 1}
    predicted_labels = [label_mapping[label] for label in predicted_labels]

    # GPU memory management, delete tensors and clear cache 
    model, tokenizer, inputs, outputs = None, None, None, None
    batch_texts, batch_predicted_labels = None, None
    torch.cuda.empty_cache()

    return predicted_labels

"""### Initial results"""

# Train and predict on tweeets with emojis (df1)
RoBERTa_train(df1_train)
predicted_sentiments1 = RoBERTa_predict(df1_val)

# Make classification report
cr_df1 = class_report(list(df1_val['Sentiment']), predicted_sentiments1)

# Train and predict on tweeets with translated emojis (df1_1)
RoBERTa_train(df1_1_train)
predicted_sentiments1_1 = RoBERTa_predict(df1_1_val)

# Make classification report
cr_df1_1 = class_report(list(df1_1_val['Sentiment']), predicted_sentiments1_1)

# Train and predict on tweeets without emojis (df2)
RoBERTa_train(df2_train)
predicted_sentiments2 = RoBERTa_predict(df2_val)

# Make classification report
cr_df2 = class_report(list(df2_val['Sentiment']), predicted_sentiments2)

print('With emojis (df1)')
print(cr_df1)
print('With translated emojis (df1_1)')
print(cr_df1_1)
print('Without emojis (df2)')
print(cr_df2)

"""## Tuning"""

def accuracy(predictions, labels):
    correct = sum(pred == label for pred, label in zip(predictions, labels))
    total = len(predictions)
    acc = correct / total
    return acc

# maybe better to just use accuracy_score from sklearn.metrics, just
# don't want to spend time on changing code until everything works

"""### Learning rate tuning"""

# Create empty lists for storing validation accuracies
val_accuracies = []

# Create empty list for storing training times
train_times = []

# Set up learning rate schedule
learning_rates = [0.0006, 0.0002, 0.00006, 0.00002, 
                  0.000006, 0.000002, 0.0000006, 0.0000002]

for rate in learning_rates:
  # Train the model for the given learning rate
  start_time = time.time()
  RoBERTa_train(df1_train, learning_rate = rate)

  # Get training time and append it
  training_time = time.time() - start_time
  train_times.append(training_time)

  # Predict on the validation data
  val_predictions = RoBERTa_predict(df1_val)

  # Calculate accuracy on validation data and append it
  val_accuracy = accuracy(df1_val['Sentiment'], val_predictions)
  val_accuracies.append(val_accuracy)

# Print results 
results = zip(learning_rates, val_accuracies, train_times)
headers = ["Learning Rate", "Val Accuracy", "Training Time"]
print(tabulate(results, headers=headers, tablefmt="grid"))

# Plot accuracy for different learning rates
plt.figure(figsize=(8, 4))
plt.plot(range(len(learning_rates)), val_accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.xticks(range(len(learning_rates)), learning_rates)
plt.ylabel('Accuracy')
plt.title('Accuracies for Learning Rates')
plt.grid(True)
plt.tight_layout()
plt.show()

"""### Batch size tuning"""

# Create empty lists for storing training and validation accuracies
val_accuracies = []
train_accuracies = []

# Create empty list for storing training times
train_times = []

# Set up batch size rate schedule
batch_sizes = [2, 4, 8, 16, 32, 64, 128, 256]
for batch in batch_sizes:
  # Start training time
  start_time = time.time()
  
  # Train the model for the given batch_size
  RoBERTa_train(df1_train, batch_size = batch, learning_rate = 2e-5)

  # Get training time and append it
  training_time = time.time() - start_time
  train_times.append(training_time)

  # Predict on the training data and validation data
  val_predictions = RoBERTa_predict(df1_val)
  train_predictions = RoBERTa_predict(df1_train)

  # Calculate accuracy on validation data and append it
  val_accuracy = accuracy(df1_val['Sentiment'], val_predictions)
  val_accuracies.append(val_accuracy)

  # Calculate accuracy on training data and append it
  train_accuracy = accuracy(df1_train['Sentiment'], train_predictions)
  train_accuracies.append(train_accuracy)

# Print results 
results = zip(batch_sizes, train_accuracies, val_accuracies, train_times)
titles = ["Batch Size", "Train Accuracy", "Val Accuracy", "Train Time"]
print(tabulate(results, headers=titles, tablefmt="grid"))

# Plot training accuracy, validation accuracy for different number of batches
plt.figure(figsize=(8, 4))
plt.plot(range(len(batch_sizes)), val_accuracies, marker='o', label='Validation Accuracy')
plt.plot(range(len(batch_sizes)), train_accuracies, marker='o', label='Training Accuracy')
plt.xlabel('Batch sizes')
plt.xticks(range(len(batch_sizes)), batch_sizes)
plt.ylabel('Accuracy')
plt.title('Accuracies for Batch Sizes')
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

"""### Epoch tuning"""

# Create empty lists for storing training and validation accuracies
val_accuracies = []
train_accuracies = []

# Create empty list for storing training times
train_times = []

# Set up epochs
eps = [1,2,3,4,5,6]

# Set up counter to monitor progress 
loop_count = 0
for ep in eps:
  loop_count += 1
  print('Start of loop number:', loop_count)
  # Start training time
  start_time = time.time()
  # Train the model for the given batch_size
  RoBERTa_train(df1_train, epochs = ep, learning_rate=2e-5, batch_size=16)
  # Get training time and append it
  training_time = time.time() - start_time
  train_times.append(training_time)

  # Predict on the training data and validation data
  val_predictions = RoBERTa_predict(df1_val)
  train_predictions = RoBERTa_predict(df1_train)

  # Calculate accuracy on validation data and append it
  val_accuracy = accuracy(df1_val['Sentiment'], val_predictions)
  val_accuracies.append(val_accuracy)

  # Calculate accuracy on training data and append it
  train_accuracy = accuracy(df1_train['Sentiment'], train_predictions)
  train_accuracies.append(train_accuracy)

from tabulate import tabulate
# Print results 
results = zip(eps, train_accuracies, val_accuracies, train_times)
titles = ["Epoch number", "Train Accuracy", "Val Accuracy", "Train Time"]
print(tabulate(results, headers=titles, tablefmt="grid"))

# Plot training accuracy, validation accuracy for different number of epochs
plt.figure(figsize=(8, 4))
plt.plot(range(len(eps)), val_accuracies, marker='o', label='Validation Accuracy')
plt.plot(range(len(eps)), train_accuracies, marker='o', label='Training Accuracy')
plt.xlabel('Epochs')
plt.xticks(range(len(eps)), eps)
plt.ylabel('Accuracy')
plt.title('Accuracy for Number of Epochs')
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

"""## Testing"""

# With emojis (df1)
RoBERTa_train(df1_train, learning_rate = 2e-5, batch_size=16, epochs = 2)
df1_predictions = RoBERTa_predict(df1_test)
cl_1 = class_report(df1_test["Sentiment"], df1_predictions)

print(cl_1)
plot_confusion_matrix(df1_test["Sentiment"], df1_predictions)

# With translated emojis (df1_1)
RoBERTa_train(df1_1_train, learning_rate = 2e-5, batch_size=16, epochs = 2)
df1_1_predictions = RoBERTa_predict(df1_1_test)
cl_1_1 = class_report(df1_1_test["Sentiment"], df1_1_predictions)

print(cl_1_1)
plot_confusion_matrix(df1_1_test["Sentiment"], df1_1_predictions)

# Without emojis (df2)
RoBERTa_train(df2_train, learning_rate = 2e-5, batch_size=16, epochs = 2) 
df2_predictions = RoBERTa_predict(df2_test)
cl_2 = class_report(df2_test["Sentiment"], df2_predictions)

print(cl_2)
plot_confusion_matrix(df2_test["Sentiment"], df2_predictions)